# ZooKeeper

## 简介

ZooKeeper 是一个分布式的、开放源码的**分布式应用程序协调服务**，是 Google 的 Chubby 一个开源的实现。分布式应用程序可以基于它实现统一命名服务、状态同步服务、集群管理、分布式应用配置项的管理等工作。

ZooKeeper 作为一个分布式的服务框架，主要用来解决分布式集群中应用系统的一致性问题，它能提供基于类似于文件系统的目录节点树方式的数据存储，ZooKeeper 作用主要是用来维护和监控存储的数据的状态变化，通过监控这些数据状态的变化，从而达到基于数据的集群管理。简单的说，ZooKeeper = 文件系统 + 通知机制。

**ZK特性：**

1. 一致性：client不论连接到哪个server，展示给它都是同一个视图，这是ZooKeeper最重要的性能。
2. 可靠性：具有简单、健壮、良好的性能，如果消息m被到一台服务器接受，那么它将被所有的服务器接受。
3. 实时性：ZooKeeper保证客户端将在一个时间间隔范围内获得服务器的更新信息，或者服务器失效的信息。但由于网络延时等原因，Zookeeper不能保证两个客户端能同时得到刚更新的数据，如果需要最新数据，应该在读数据之前调用sync()接口。
4. 等待无关：慢的或者失效的client不得干预快速的client的请求，使得每个client都能有效的等待。
5. 原子性：更新只能成功或者失败，没有中间状态。
6. 顺序性：包括全局有序和偏序两种。全局有序是指如果在一台服务器上消息a在消息b前发布，则在所有server上消息a都将在消息b前被发布；偏序是指如果一个消息b在消息a后被同一个发送者发布，a必将排在b前面。

> https://zookeeper.apache.org/doc/current/zookeeperOver.html
>
> [ZooKeeper介绍与核心概念](https://blog.csdn.net/liyiming2017/article/details/83035157?spm=1001.2014.3001.5501)
>
> [安装和使用](https://blog.csdn.net/liyiming2017/article/details/83501836)
>
> [ZooKeeper分布式锁实现](https://blog.csdn.net/liyiming2017/article/details/83786331)
>
> [ZooKeeper框架Curator分布式锁实现及源代码分析](https://blog.csdn.net/liyiming2017/article/details/83896169)
>
> [ZooKeeper 开发实战（java客户端）](https://blog.csdn.net/liyiming2017/article/details/85063868)
>
> [ZooKeeper C API 常用函数详解](https://blog.csdn.net/xiaoliantongtong/article/details/99954363)

## 应用场景

**一、数据发布与订阅**

发布与订阅即所谓的配置管理，顾名思义就是将数据发布到zk节点上，供订阅者动态获取数据，实现配置信息的集中式管理和动态更新。例如全局的配置信息，地址列表等就非常适合使用。

1. 索引信息和集群中机器节点状态存放在zk的一些指定节点，供各个客户端订阅使用。
2. 系统日志（经过处理后的）存储，这些日志通常2-3天后被清除。
3. 应用中用到的一些配置信息集中管理，在应用启动的时候主动来获取一次，并且在节点上注册一个Watcher，以后每次配置有更新，实时通知到应用，获取最新配置信息。
4. 业务逻辑中需要用到的一些全局变量，比如一些消息中间件的消息队列通常有个offset，这个offset存放在zk上，这样集群中每个发送者都能知道当前的发送进度。
5. 系统中有些信息需要动态获取，并且还会存在人工手动去修改这个信息。以前通常是暴露出接口，例如JMX接口，有了zk后，只要将这些信息存放到zk节点上即可。

**二、分布通知/协调**

ZooKeeper 中特有watcher注册与异步通知机制，能够很好的实现分布式环境下不同系统之间的通知与协调，实现对数据变更的实时处理。使用方法通常是不同系统都对 ZK上同一个znode进行注册，监听znode的变化（包括znode本身内容及子节点），其中一个系统update了znode，另一个系统能够收到通知，并作出相应处理。

1. 另一种心跳检测机制：检测系统和被检测系统之间并不直接关联起来，而是通过zk上某个节点关联，大大减少系统耦合。
2. 另一种系统调度模式：某系统有控制台和推送系统两部分组成，控制台的职责是控制推送系统进行相应的推送工作。管理人员在控制台作的一些操作，实际上是修改 了ZK上某些节点的状态，而zk就把这些变化通知给他们注册Watcher的客户端，即推送系统，于是，作出相应的推送任务。
3. 另一种工作汇报模式：一些类似于任务分发系统，子任务启动后，到zk来注册一个临时节点，并且定时将自己的进度进行汇报（将进度写回这个临时节点），这样任务管理者就能够实时知道任务进度。

总之，使用zookeeper来进行分布式通知和协调能够大大降低系统之间的耦合。

**三、分布式锁**

分布式锁，这个主要得益于ZooKeeper为我们保证了数据的强一致性，即用户只要完全相信每时每刻，zk集群中任意节点（一个zk server）上的相同znode的数据是一定是相同的。锁服务可以分为两类，一个是保持独占，另一个是控制时序。

1. 保持独占，就是所有试图来获取这个锁的客户端，最终只有一个可以成功获得这把锁。通常的做法是把zk上的一个znode看作是一把锁，通过create znode的方式来实现。所有客户端都去创建 /distribute_lock 节点，最终成功创建的那个客户端也即拥有了这把锁。
2. 控制时序，就是所有视图来获取这个锁的客户端，最终都是会被安排执行，只是有个全局时序了。做法和上面基本类似，只是这里 /distribute_lock 已经预先存在，客户端在它下面创建临时有序节点（这个可以通过节点的属性控制：CreateMode.EPHEMERAL_SEQUENTIAL来指定）。Zk的父节点（/distribute_lock）维持一份sequence，保证子节点创建的时序性，从而也形成了每个客户端的全局时序。

**四、集群管理**

1. 集群机器监控：这通常用于那种对集群中机器状态，机器在线率有较高要求的场景，能够快速对集群中机器变化作出响应。这样的场景中，往往有一个监控系统，实时检测集群机器是否存活。过去的做法通常是：监控系统通过某种手段（比如ping）定时检测每个机器，或者每个机器自己定时向监控系统汇报“我还活着”。 这种做法可行，但是存在两个比较明显的问题：1. 集群中机器有变动的时候，牵连修改的东西比较多。2. 有一定的延时。

   利用ZooKeeper有两个特性，就可以实时另一种集群机器存活性监控系统：a. 客户端在节点 x 上注册一个Watcher，那么如果 x 的子节点变化了，会通知该客户端。b. 创建EPHEMERAL类型的节点，一旦客户端和服务器的会话结束或过期，那么该节点就会消失。

2. Master选举：zookeeper中最为经典的使用场景，在分布式环境中，相同的业务应用分布在不同的机器上，有些业务逻辑（例如一些耗时的计算，网络I/O处理），往往只需要让整个集群中的某一台机器进行执行， 其余机器可以共享这个结果，这样可以大大减少重复劳动，提高性能，于是这个master选举便是这种场景下的碰到的主要问题。

   利用ZooKeeper的强一致性，能够保证在分布式高并发情况下节点创建的全局唯一性，即：同时有多个客户端请求创建 /currentMaster 节点，最终一定只有一个客户端请求能够创建成功。

 

# Kafka

## 简介

Kafka 是由 Linkedin 公司开发的，它是一个分布式的，支持多分区、多副本，基于 Zookeeper 的分布式消息流平台，它同时也是一款开源的**基于发布订阅模式的消息引擎系统**。

<img src="https://images.gitbook.cn/e49bc290-cf95-11e8-8388-bd48f25029c6" alt="enter image description here" style="zoom:50%;" />

一个典型的 Kafka 体系架构包括若干 Producer，若干 broker（ Kafka 节点的服务器），若干 Consumer，以及一个 ZooKeeper 集群。Kafka通过 ZooKeeper 管理集群配置、选举 Leader 以及在 consumer group 发生变化时进行 Rebalance。Producer 使用 push 模式将消息发布到 broker，Consumer 使用 pull 模式从 broker 订阅并消费消息。

> [深入浅出理解基于 Kafka 和 ZooKeeper 的分布式消息队列](https://gitbook.cn/books/5ae1e77197c22f130e67ec4e/index.html)

## 系统架构

<img src="https://images.gitbook.cn/4b558580-cafe-11e8-ba64-19e24fcb4ae1" alt="拓扑结构"  />

- **Producer**：生产者，push 消息到 Kafka 集群中的 broker 中。
- **Broker**：Kafka 集群由多个 Kafka 实例（server） 组成。
- **Topic**：producer 向 kafka 集群 push 的消息会被归于某一类别，即Topic，这本质上只是一个逻辑概念，面向的对象是 producer 和 consumer，producer 只需要关注将消息 push 到哪一个 Topic 中，而 consumer 只需要关心自己订阅了哪个 Topic。
- **Partition**：每一个 Topic 又被分为多个 Partitions，即物理分区；出于负载均衡的考虑，同一个 Topic 的 Partitions 分别存储于 Kafka 集群的多个 broker 上；而为了提高可靠性，这些 Partitions 可以由 Kafka 机制中的 replicas 来设置备份的数量。
- **Consumer**：消费者，从 Kafka 集群的 broker 中 pull 消息。
- **Consumer Group**：high-level consumer API 中，每个 consumer 都属于一个 consumer-group，每条消息只能被 consumer-group 中的一个 Consumer 消费，但可以被多个 consumer-group 消费。
- **replicas**：partition 的副本，保障 partition 的高可用。
- **leader**：replicas 中的一个角色， producer 和 consumer 只跟 leader 交互。
- **follower**：replicas 中的一个角色，从 leader 中复制数据，作为副本，一旦 leader 挂掉，会从它的 followers 中选举出一个新的 leader 继续提供服务。
- **controller**：Kafka 集群中的其中一个服务器，用来进行 leader election 以及 各种 failover。



1. **Topic 与 Partition**

    > 一个 topic 可以认为是一类消息，每个 topic 将被分成多个 partition，每个 partition 在存储层面是 append log 文件。任何发布到此 partition 的消息都会被追加到log文件的尾部，每条消息在文件中的位置称为 offset（偏移量）。Kafka 机制中，producer push 来的消息是追加（append）到 partition 中的，这是一种顺序写磁盘的机制，效率远高于随机写内存。
    >
    > <img src="https://images.gitbook.cn/7ffb6db0-cb01-11e8-9b13-63a667cc1a24" alt="enter image description here" style="zoom: 33%;" />
2. **为什么要将 Topic 进行分区**

    > 简而言之：负载均衡 + 水平扩展。
    >
    > Topic 只是逻辑概念，面向的是 producer 和 consumer，而 Partition 则是物理概念。如果 Topic 不进行分区，而将 Topic 内的消息存储于一个 broker，那么关于该 Topic 的所有读写请求都将由这一个 broker 处理，吞吐量很容易陷入瓶颈。
    >
    > Partiton 机制可以极大的提高吞吐量，并且使得系统具备良好的水平扩展能力。假设一个 Topic 被分为 10 个 Partitions，Kafka 会根据一定的算法将 10 个 Partition 尽可能均匀的分布到不同的 broker（服务器）上，当 producer 发布消息时，producer 客户端可以采用算法选定目标 partition。在发送一条消息时，可以指定这个消息的 key，producer 根据这个 key 和 partition 机制来判断这个消息发送到哪个 partition。

3. **Kafka 高可靠性实现**

    > 谈及可靠性，最常规、最有效的策略就是 “副本（replication）机制” ，Kafka 实现高可靠性同样采用了该策略。
    >
    > **1、Kafka 文件存储机制**
    >
    > 可以想象，当 Kafka producer 不断发送消息，必然会引起 partition 文件的无限扩张，将对消息文件的维护以及已消费的消息的清理带来严重的影响，因此，需以 segment 为单位将 partition 进一步细分。每个 partition（目录）相当于一个巨型文件被平均分配到多个大小相等的 segment（段）数据文件中，这种特性也方便 old segment 的删除，提高磁盘的利用率。
    >
    > 一个 partition 上由多个 segment 组成；segment 文件由两部分组成，分别为 “.index” 文件和 “.log” 文件，分别表示为 segment 索引文件和数据文件。
    >
    > <img src="https://images.gitbook.cn/60eafc10-cc9b-11e8-b452-15eec1b99303" alt="enter image description here" style="zoom: 67%;" />
    >
    > “.index” 索引文件存储大量的元数据，“.log” 数据文件存储大量的消息，索引文件中的元数据指向对应数据文件中 message 的物理偏移地址。其中以 “.index” 索引文件中的元数据 [3, 348] 为例，在 “.log” 数据文件表示第 3 个消息，即在全局 partition 中表示 170410+3=170413 个消息，该消息的物理偏移地址为 348。
    >
    > **2、复制原理和同步方式**
    >
    > 为了提高消息的可靠性，Kafka 每个 topic 的 partition 有 N 个副本（replicas），其中 N 是 topic 的复制因子的个数。Kafka 通过多副本机制实现故障自动转移，当 Kafka 集群中出现 broker 失效时，副本机制可保证服务可用。
    >
    > 对于任何一个 partition，它的 N 个 replicas 中，其中一个 replica 为 leader，其他都为 follower，leader 负责处理 partition 的所有读写请求，follower 则负责被动地去复制 leader 上的数据。如下图所示，Kafka 集群中有 4 个 broker，某 topic 有 3 个 partition，且复制因子即副本个数也为 3。
    >
    > <img src="https://images.gitbook.cn/616acd70-cf9b-11e8-8388-bd48f25029c6" alt="enter image description here" style="zoom:50%;" />
    >
    > 如果 leader 所在的 broker 发生故障或宕机，对应 partition 将因无 leader 而不能处理客户端请求，这时副本的作用就体现出来了：一个新 leader 将从 follower 中被选举出来并继续处理客户端的请求。

4. **ZooKeeper 作用**

    > 在基于 Kafka 的分布式消息队列中，ZooKeeper 的作用有：broker 注册、topic 注册、producer 和 consumer 负载均衡、维护 partition 与 consumer 的关系、记录消息消费的进度以及 consumer 注册等。

## librdkafka

librdkafka 是一个C实现的高性能 Apache Kafka 客户端，为生产环境提供了一个可靠和高性能的客户端。librdkafka 同样也提供了传统的 C++ 接口。

- 创建kafka配置：rd_kafka_conf_new()
- 配置kafka参数：rd_kafka_conf_set()
- 设置回调函数：rd_kafka_conf_set_dr_msg_cb()
- 创建topic：rd_kafka_topic_new()
- 配置topic参数：rd_kafka_topic_conf_set()
- 销毁topic：rd_kafka_topic_destroy()
- 创建producer实例：rd_kafka_new()
- 销毁producer实例：rd_kafka_destroy()
- 异步发送消息：rd_kafka_produce()
- 同步发送消息：rd_kafka_poll()
- 添加brokerlist：rd_kafka_brokers_add()
- 开启consumer订阅：rd_kafka_subscribe()
- 轮询消息或事件，调用回调函数：rd_kafka_consumer_poll()
- 关闭consumer实例：rd_kafka_consumer_close()



# Protobuf

Protobuf（Protocol Buffers ）是 Google 的开源项目，是 Google 中立于语言、平台，可扩展的用于序列化结构化数据的解决方案。简单地说，protobuf 是用来对数据进行序列化和反序列化。

> [Protocol Buffer Basics: C++](https://www.cnblogs.com/cposture/p/9029033.html)



# Nginx

Nginx (engine x) 是一个开源的，支持高性能、高并发的 Web 服务和代理服务软件。

> [Nginx 介绍](https://www.cnblogs.com/wushuaishuai/p/9366402.html)
>
> [Nginx 配置详解](https://www.runoob.com/w3cnote/nginx-setup-intro.html)、[Nginx 反向代理与负载均衡详解](https://www.runoob.com/w3cnote/nginx-proxy-balancing.html)



# OpenCV

OpenCV（Open Source Computer Vision）是 Intel 开源计算机视觉库，由一系列 C 函数和少量 C++ 类构成，实现了图像处理和计算机视觉方面的很多通用算法。

> https://docs.opencv.org/4.1.2/index.html

| 模块    | 说明                                                         | 库                                                           |
| ------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| Core    | 该模块包含 OpenCV 库的基础结构以及基本操作。                 | libopencv_core.so                                            |
| Improc  | 图像处理模块包含基本的图像转换，包括滤波以及类似的卷积操作。 | libopencv_imgproc.so                                         |
| Highgui | OpenCV3.0中分为三部分：imcodecs、videoio、highgui，包含用来显示图像或者简单输入的交互函数，可以看作是一个轻量级的UI工具包。 | libopencv_imgcodecs.so<br />libopencv_videoio.so<br />libopencv_highgui.so |
| Video   | 该模块包含读写视频流的函数。                                 | libopencv_video.so                                           |



# FFmpeg

FFmpeg 是一个集录制、转换、音视频编码解码功能为一体的完整的开源解决方案。基于 Linux 操作系统开发，可以在大多数系统中编译和使用。

> [FFMPEG视音频编解码零基础学习](https://blog.csdn.net/leixiaohua1020/article/details/15811977)

1. 工具程序
   - ffmpeg：音视频转换器转换多媒体文件之间的格式的一个命令行工具。
   - ffserver：用ffmpeg实现的RTSP服务器，用于实时广播的串流服务器。
   - ffplay：简单的媒体播放器使用ffmpeg解析和解码，通过SDL显示。
   - ffprobe：多媒体流分析工具，从多媒体流中收集信息，以可读的形式打印出来。

2. 开发者库
   - libavutil：核心工具，工具函数、内存操作等常用模块。
   - libavcodec：音视频编解码器库
   - libavformat：音视频格式转换库



# OpenGL

OpenGL（Open Graphics Library）是个专业的图形程序接口，定义了一个跨编程语言、跨平台的编程接口规格。它是一个功能强大，调用方便的底层三维图形处理库，也是该领域的工业标准。

> [ LearnOpenGL](https://learnopengl-cn.github.io/)



# Curl

Curl 是常用的命令行工具，用来请求 Web 服务器。

libcurl 是一个易用的，支持多协议的 URL 传输库，基于网络协议，对指定 URL 进行网络传输。支持众多的协议，如 FTP、HTTP、HTTPS、IMAP、POP3、SMTP、TELNET等，同时 libcurl 支持 SSL 验证，基于 HTTP 协议的文件上传，代理，客户端缓冲等。

> [curl 用法指南](https://blog.csdn.net/gxzhaha/article/details/112399851)
>
> [libcurl 使用（C++）](https://blog.csdn.net/MOU_IT/article/details/96457666)



# OpenSSL

OpenSSL 是为网络通信提供安全及数据完整性的一种安全协议，囊括了主要的密码算法、常用的密钥和证书封装管理功能以及 SSL 协议，并提供了丰富的应用程序供测试或其它目的使用。

OpenSSL 是一个开源的程序套件，由三部分组成：

- libcrypto：通用功能的加密库，实现了众多加密算法。
- libssl：实现了ssl/tls功能。
- openssl：多功能的命令行工具，可以实现加密解密、自建CA、创建证书、吊销证书。





> 【GitHub搜索】in:name/readme/description 关键词 language:python star:>1000 fork:>500 pushed:>2020-1-1 